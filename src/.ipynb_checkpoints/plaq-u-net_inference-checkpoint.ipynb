{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plaq-u-net: multi-patch consensus U-Net for automated detection and segmentation of the carotid arteries on black blood MRI sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Lavrova, 2022\n",
    "\n",
    "This is a code supporting the corresponding paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "import pydicom\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import img_as_float\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0416 10:23:58.438442 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0416 10:23:58.441442 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0416 10:23:58.445449 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0416 10:24:02.241980 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'                        \n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 8, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    smooth=1\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    from keras.losses import binary_crossentropy\n",
    "    return 0.5*keras.losses.binary_crossentropy(y_true,y_pred)+0.5*dice_loss(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models compilation + loading weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0416 10:24:23.053368 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0416 10:24:24.570311 24072 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im_height = 64\n",
    "im_width = 64\n",
    "\n",
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "\n",
    "model_simple = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_simple.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model_simple.load_weights('../res/plaq-u-net_simple.h5')\n",
    "\n",
    "model_aug = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_aug.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model_aug.load_weights('../res/plaq-u-net_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patching and consensus map calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect4multipatches(img, model):\n",
    "    \n",
    "    steps = int((img.shape[0]-64)/4)+1\n",
    "    \n",
    "    M = np.empty((img.shape[0], img.shape[1], steps*steps))\n",
    "    M[:] = np.NaN\n",
    "    img_patch = np.zeros((steps*steps, 64, 64, 1))\n",
    "    c = 0\n",
    "\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            \n",
    "            img_crop = img[4*i:4*i+64, 4*j:4*j+64]\n",
    "            img_patch[c, ..., 0] = img_crop.copy()\n",
    "            c += 1\n",
    "            \n",
    "    img_patch_pred = model.predict(img_patch, verbose=0)\n",
    "    \n",
    "    c = 0\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            M[4*i:4*i+64, 4*j:4*j+64, c] = img_patch_pred[c, ..., 0]\n",
    "            c += 1\n",
    "            \n",
    "    M_concord = np.nanmean(M, axis = 2)\n",
    "    \n",
    "    del M\n",
    "            \n",
    "    return M_concord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CA probability maps calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data loading and pre-processing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading DICOM to array from the file path\n",
    "def path2array(dcm_path):\n",
    "    arr_dcm = pydicom.read_file(dcm_path, force = True)\n",
    "    arr_dcm.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "    arr = arr_dcm.pixel_array\n",
    "    return arr\n",
    "\n",
    "# N4 bias field correction\n",
    "def correctBiasField(img_input):\n",
    "    \n",
    "    corrected = False\n",
    "    img_output = np.zeros(img_input.shape)\n",
    "\n",
    "    while not corrected:\n",
    "\n",
    "        try:\n",
    "            corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "            inputImage = sitk.GetImageFromArray(img_input)\n",
    "            inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "            output = corrector.Execute(inputImage)\n",
    "            img_output = sitk.GetArrayFromImage(output)\n",
    "            corrected = True\n",
    "        except:\n",
    "            print ('BFC failed')\n",
    "\n",
    "    return img_output\n",
    "\n",
    "# zooming images to defined voxel size and array shape (with cropping/padding)\n",
    "# from: https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting patient names from the test set (from training script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_test = ['AMC012', 'AMC006', 'MUMC094', 'MUMC027', 'MUMC079', 'MUMC052', 'MUMC127', 'MUMC071', 'MUMC038',\n",
    "                  'MUMC093', 'MUMC107', 'MUMC022', 'MUMC114', 'MUMC115', 'MUMC069', 'MUMC130', 'MUMC036', 'MUMC007', \n",
    "                  'MUMC059', 'MUMC080', 'UMCU036', 'UMCU025', 'UMCU008', 'UMCU034']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating CA probability maps and saving to the results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFC failed\n",
      "BFC failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_test:\n",
    "    \n",
    "    os.mkdir(results_dir_simple+sub_name)\n",
    "    os.mkdir(results_dir_aug+sub_name)\n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        #img_test = correctBiasField(img[8:-8,8:-8])\n",
    "        img_test = img[8:-8,8:-8].copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "        vessels_pred_multi_simple = detect4multipatches(img_norm, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_norm, model_aug)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_simple)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', \n",
    "                vessels_pred_multi_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 EMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient names from EMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_emc = ['EMC003', 'EMC004', 'EMC005', 'EMC007', 'EMC008', 'EMC009', 'EMC011', \n",
    "                 'EMC015', 'EMC018', 'EMC020', 'EMC024', 'EMC027', 'EMC029', 'EMC031', \n",
    "                 'EMC032', 'EMC034', 'EMC035', 'EMC036', 'EMC038', 'EMC041', 'EMC042', \n",
    "                 'EMC043', 'EMC045', 'EMC046', 'EMC047', 'EMC048', 'EMC049', 'EMC050', \n",
    "                 'EMC051', 'EMC052', 'EMC054', 'EMC055', 'EMC056', 'EMC057']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating CA probability maps and saving to the results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n",
      "BFC failed\n"
     ]
    }
   ],
   "source": [
    "ds_dir = '../data/'\n",
    "results_dir_simple = '../res/maps/plaq-u-net_simple/'\n",
    "results_dir_aug = '../res/maps/plaq-u-net_aug/'\n",
    "\n",
    "for sub_name in sub_names_emc:\n",
    "    \n",
    "    os.mkdir(results_dir_simple+sub_name)\n",
    "    os.mkdir(results_dir_aug+sub_name)\n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        #img_test = correctBiasField(img)\n",
    "        img_test = img.copy()\n",
    "        img_min = np.min(img_test)\n",
    "        img_max = np.max(img_test)\n",
    "        img_norm = np.copy((img_test - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "        \n",
    "        img_res = cv2.resize(img_norm.copy(), dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vessels_pred_multi_simple = detect4multipatches(img_res, model_simple)\n",
    "        vessels_pred_multi_aug = detect4multipatches(img_res, model_aug)\n",
    "        \n",
    "        vessels_pred_multi_simple_res = cv2.resize(vessels_pred_multi_simple.copy(), \n",
    "                                                   dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        vessels_pred_multi_aug_res = cv2.resize(vessels_pred_multi_aug.copy(), \n",
    "                                                dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        np.save(results_dir_simple + sub_name + '/' + sub_img_name.split(os.sep)[2][-17:-11] + '.npy', \n",
    "                vessels_pred_multi_simple_res)\n",
    "        np.save(results_dir_aug + sub_name + '/' + sub_img_name.split(os.sep)[2][-17:-11] + '.npy', \n",
    "                vessels_pred_multi_aug_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
